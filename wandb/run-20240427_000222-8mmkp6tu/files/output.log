Overriding model.yaml nc=1 with nc=8
                 from  n    params  module                                  arguments
  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]
  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  2                -1  3    156928  models.common.C3                        [128, 128, 3]
  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]
  4                -1  6   1118208  models.common.C3                        [256, 256, 6]
  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]
  6                -1  9   6433792  models.common.C3                        [512, 512, 9]
  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]
  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]
  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]
 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]
 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]
 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]
 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]
/data1/jiahaoguo/miniconda3/envs/transvisdrone/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
 24      [17, 20, 23]  1  33249389  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024], 5]
creating temporal trans 5, [256, 512, 1024]
Model Summary: 565 layers, 79355373 parameters, 79355373 gradients
Transferred 684/691 items from runs/train/NPS/image_size_1280_temporal_YOLO5l_5_frames_NPS_end_to_end_skip_0/weights/last.pt, excluding ['anchor']
Scaled weight_decay = 0.00036
[34m[1moptimizer:[39m[22m Adam with parameter groups 101 weight, 140 weight (no decay), 134 bias
DP not recommended, instead use torch.distributed.run for best DDP Multi-GPU results.
See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.
Frame wise augmentation set to 1
[34m[1malbumentations: [39m[22mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.3, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.3, clip_limit=(1, 4.0), tile_grid_size=(8, 8)), RandomBrightnessContrast(always_apply=False, p=0.3, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True)
[34m[1mtrain: [39m[22mScanning '/data1/jiahaoguo/dataset/UAVTOD_1/all/yolo.cache' images and labels... 7426 found, 0 missing, 7 empty, 0
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0824Part2_1/0000020.png: 2 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000062.png: 28 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000063.png: 28 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000064.png: 28 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000066.png: 96 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000067.png: 69 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000074.png: 23 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000078.png: 20 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000080.png: 19 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000062.png: 43 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000063.png: 42 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000064.png: 42 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000066.png: 168 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000067.png: 126 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000074.png: 41 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000078.png: 38 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000080.png: 38 duplicate labels removed
[34m[1mval: [39m[22mScanning '/data1/jiahaoguo/dataset/UAVTOD_1/all/yolo.cache' images and labels... 7426 found, 0 missing, 7 empty, 0 co
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0824Part2_1/0000020.png: 2 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000062.png: 28 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000063.png: 28 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000064.png: 28 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000066.png: 96 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000067.png: 69 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000074.png: 23 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000078.png: 20 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_0/0000080.png: 19 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000062.png: 43 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000063.png: 42 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000064.png: 42 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000066.png: 168 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000067.png: 126 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000074.png: 41 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000078.png: 38 duplicate labels removed
[34m[1mtrain: [39m[22mWARNING: /data1/jiahaoguo/dataset/UAVTOD_1/images/./UAVTOD_DJI0825Part31_1/0000080.png: 38 duplicate labels removed
Shuffling indices because training
data loader shuffle True
Frame wise augmentation set to 1
data loader shuffle False
Number of val loader workers 2
Plotting labels...
Image sizes 1024 train, 1024 val
Using 0 dataloader workers
Logging results to [1mruns/train/testUSVID/visualization_5_frames
Starting training for 80 epochs...
     Epoch   gpu_mem       box       obj       cls    labels  img_size
  0%|                                                                                            | 0/7419 [00:00<?, ?it/s]
[34m[1mautoanchor: [39m[22mAnalyzing anchors... anchors/target = 3.36, Best Possible Recall (BPR) = 0.9928
24
torch.Size([1, 256, 128, 128])
torch.Size([1, 512, 64, 64])
torch.Size([1, 512, 32, 32])
torch.Size([1, 256, 64, 64])
torch.Size([1, 256, 128, 128])
torch.Size([1, 512, 64, 64])
torch.Size([1, 1024, 32, 32])
torch.Size([2, 256, 128, 128])
torch.Size([2, 512, 64, 64])
torch.Size([2, 512, 32, 32])
torch.Size([2, 256, 64, 64])
torch.Size([2, 256, 128, 128])

