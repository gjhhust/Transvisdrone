
creating temporal trans 5, [256, 512, 1024]
Overriding model.yaml nc=1 with nc=8
                 from  n    params  module                                  arguments
  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]
  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  2                -1  3    156928  models.common.C3                        [128, 128, 3]
  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]
  4                -1  6   1118208  models.common.C3                        [256, 256, 6]
  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]
  6                -1  9   6433792  models.common.C3                        [512, 512, 9]
  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]
  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]
  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]
 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]
 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]
 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]
 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]
/data1/jiahaoguo/miniconda3/envs/transvisdrone/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
 24      [17, 20, 23]  1  33249389  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024], 5]
Model Summary: 565 layers, 79355373 parameters, 79355373 gradients
Transferred 684/691 items from runs/train/NPS/image_size_1280_temporal_YOLO5l_5_frames_NPS_end_to_end_skip_0/weights/last.pt, excluding ['anchor']
Scaled weight_decay = 0.00036
[34m[1moptimizer:[39m[22m Adam with parameter groups 101 weight, 140 weight (no decay), 134 bias
DP not recommended, instead use torch.distributed.run for best DDP Multi-GPU results.
See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.
Frame wise augmentation set to 1
[34m[1malbumentations: [39m[22mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.3, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.3, clip_limit=(1, 4.0), tile_grid_size=(8, 8)), RandomBrightnessContrast(always_apply=False, p=0.3, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True)
Traceback (most recent call last):
  File "/data1/jiahaoguo/miniconda3/envs/transvisdrone/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data1/jiahaoguo/miniconda3/envs/transvisdrone/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/jiahaoguo/.vscode-server/extensions/ms-python.debugpy-2024.4.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py", line 39, in <module>
    cli.main()
  File "/home/jiahaoguo/.vscode-server/extensions/ms-python.debugpy-2024.4.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py", line 430, in main
    run()
  File "/home/jiahaoguo/.vscode-server/extensions/ms-python.debugpy-2024.4.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py", line 284, in run_file
    runpy.run_path(target, run_name="__main__")
  File "/home/jiahaoguo/.vscode-server/extensions/ms-python.debugpy-2024.4.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 321, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/jiahaoguo/.vscode-server/extensions/ms-python.debugpy-2024.4.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 135, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/jiahaoguo/.vscode-server/extensions/ms-python.debugpy-2024.4.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 124, in _run_code
    exec(code, run_globals)
  File "/data1/jiahaoguo/TransVisDrone/train.py", line 704, in <module>
    main(opt)
  File "/data1/jiahaoguo/TransVisDrone/train.py", line 601, in main
    train(opt.hyp, opt, device, callbacks)
  File "/data1/jiahaoguo/TransVisDrone/train.py", line 262, in train
    train_loader, dataset = create_dataloader(train_path, annotation_train_path, video_root, imgsz, batch_size // WORLD_SIZE, gs, single_cls,
  File "/data1/jiahaoguo/TransVisDrone/utils/datasets.py", line 110, in create_dataloader
    dataset = LoadClipsAndLabels_my(path, annotation_path, video_root_path, imgsz, batch_size,
  File "/data1/jiahaoguo/TransVisDrone/utils/datasets.py", line 952, in __init__
    self.label_files = img2label_paths(self.img_files, self.annotation_path)  # labels
  File "/data1/jiahaoguo/TransVisDrone/utils/datasets.py", line 405, in img2label_paths
    meta_paths =[ [str(Path(x).parent.parent), get_clip_id(x), get_frame_id(x)] for x in img_paths]
  File "/data1/jiahaoguo/TransVisDrone/utils/datasets.py", line 405, in <listcomp>
    meta_paths =[ [str(Path(x).parent.parent), get_clip_id(x), get_frame_id(x)] for x in img_paths]
  File "/data1/jiahaoguo/TransVisDrone/utils/datasets.py", line 403, in <lambda>
    get_clip_id = lambda x: os.path.basename(x).split(".")[0].split("_")[1]
IndexError: list index out of range